{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-ericksonlab/micropillar-precipitation-segmentation/blob/main/micropillar_full_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c3d0d8",
      "metadata": {
        "id": "69c3d0d8"
      },
      "source": [
        "# Micropillar Dual-Mode Image Analysis Pipeline (Pillar U-Net + C2 Quantification)\n",
        "\n",
        "This single notebook is intended for **public reproducibility** (e.g., a GitHub repo for reviewers).\n",
        "It:\n",
        "\n",
        "1. **Downloads** the trained pillar-segmentation model from Box (if missing)\n",
        "2. Runs **U-Net inference** on **C1** images to create pillar masks\n",
        "3. Uses pillar masks to quantify **birefringent CaCOâ‚ƒ** signal in **C2** images\n",
        "4. Exports **per-image metrics** and **condition-aggregated summaries** as CSV\n",
        "\n",
        "**Expected naming convention (recommended):**  \n",
        "`<channel>.<section>.<diameter>.<trial>.c1.png` and `...c2.png`  \n",
        "Example: `t1.1.8.a.c1.png` and `t1.1.8.a.c2.png`\n",
        "\n",
        "If your filenames differ, update `parse_filename()` and `pair_c1_c2()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a34c0c",
      "metadata": {
        "id": "a0a34c0c"
      },
      "source": [
        "### Optional: install dependencies (Colab)\n",
        "\n",
        "If you're running in Google Colab, uncomment and run the install cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2efde8",
      "metadata": {
        "id": "4d2efde8"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (Colab / fresh environments)\n",
        "!pip -q install segmentation-models-pytorch albumentations opencv-python tqdm pandas matplotlib requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Step 1: Clone GitHub repo into Colab\n",
        "# =======================\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Set your repo URL (leave as-is if correct)\n",
        "REPO_URL = \"https://github.com/d-ericksonlab/micropillar-precipitation-segmentation.git\"\n",
        "\n",
        "REPO_NAME = REPO_URL.rstrip(\"/\").split(\"/\")[-1].replace(\".git\", \"\")\n",
        "REPO_PATH = Path(\"/content\") / REPO_NAME\n",
        "\n",
        "# Clone only if missing\n",
        "if not REPO_PATH.exists():\n",
        "    print(\"Cloning repo into Colab...\")\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(\"Repo already exists in Colab\")\n",
        "\n",
        "# Move into repo\n",
        "os.chdir(REPO_PATH)\n",
        "print(\"Working directory:\", Path.cwd())\n",
        "\n",
        "# Confirm test images folder exists\n",
        "IMG_DIR = Path(\"test_images\")\n",
        "print(\"Checking for images folder:\", IMG_DIR.resolve())\n",
        "\n",
        "if not IMG_DIR.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find {IMG_DIR.resolve()}.\\n\\n\"\n",
        "        f\"Fix: confirm test images are committed to GitHub under: {IMG_DIR}/\"\n",
        "    )\n",
        "\n",
        "# List a few files\n",
        "print(\"\\nContents of test_images (first 30):\")\n",
        "!ls -lah test_images | head -n 30\n",
        "\n",
        "# Show one sample image in output\n",
        "valid_ext = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "all_imgs = sorted([p for p in IMG_DIR.rglob(\"*\") if p.suffix.lower() in valid_ext])\n",
        "\n",
        "if len(all_imgs) == 0:\n",
        "    raise FileNotFoundError(f\"No image files found under: {IMG_DIR.resolve()}\")\n",
        "\n",
        "sample_img = all_imgs[0]\n",
        "img = cv2.imread(str(sample_img), cv2.IMREAD_UNCHANGED)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(f\"Could not read sample image: {sample_img}\")\n",
        "\n",
        "if img.ndim == 3:\n",
        "    img_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    cmap = None\n",
        "else:\n",
        "    img_show = img\n",
        "    cmap = \"gray\"\n",
        "\n",
        "print(\"\\nSample image:\")\n",
        "print(\" \", sample_img)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(img_show, cmap=cmap)\n",
        "plt.title(sample_img.name)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V1G82ybzFUxT"
      },
      "id": "V1G82ybzFUxT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Section 2: Confirm repo structure (test_images/, model/, results/)\n",
        "# =======================\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_ROOT = Path(\"test_images\")\n",
        "MODEL_DIR  = Path(\"model\")\n",
        "OUT_ROOT   = Path(\"results\")\n",
        "\n",
        "print(\"Current working directory:\", Path.cwd())\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"MODEL_DIR:\", MODEL_DIR.resolve())\n",
        "print(\"OUT_ROOT:\", OUT_ROOT.resolve())\n",
        "\n",
        "if not INPUT_ROOT.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing folder: {INPUT_ROOT.resolve()}\\n\"\n",
        "        \"Fix: confirm the repo contains test_images/ and that you cloned the repo successfully.\"\n",
        "    )\n",
        "\n",
        "# Create folders if missing (safe)\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nFolder check passed.\")\n",
        "print(\"test_images exists:\", INPUT_ROOT.exists())\n",
        "print(\"model exists:\", MODEL_DIR.exists())\n",
        "print(\"results exists:\", OUT_ROOT.exists())\n"
      ],
      "metadata": {
        "id": "d2CQ9hvV0n4X"
      },
      "id": "d2CQ9hvV0n4X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237d3df5",
      "metadata": {
        "id": "237d3df5"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Section 3: Discover images (from GitHub repo) + preview samples\n",
        "# =======================\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Paths inside the GitHub repo\n",
        "INPUT_ROOT = Path(\"test_images\")\n",
        "OUT_ROOT   = Path(\"results\")\n",
        "MODEL_DIR  = Path(\"model\")\n",
        "\n",
        "# Create required folders\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Working directory:\", Path.cwd())\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"MODEL_DIR:\", MODEL_DIR.resolve())\n",
        "print(\"OUT_ROOT:\", OUT_ROOT.resolve())\n",
        "\n",
        "# Confirm input exists\n",
        "if not INPUT_ROOT.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find INPUT_ROOT: {INPUT_ROOT.resolve()}\\n\"\n",
        "        \"Fix: confirm you committed images to test_images/ in GitHub.\"\n",
        "    )\n",
        "\n",
        "# Find all image files recursively\n",
        "valid_ext = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "all_imgs = sorted([p for p in INPUT_ROOT.rglob(\"*\") if p.suffix.lower() in valid_ext])\n",
        "\n",
        "# Detect C1 and C2 from filename\n",
        "c1_files = sorted([p for p in all_imgs if \".c1.\" in p.name.lower() or p.name.lower().endswith(\".c1.png\")])\n",
        "c2_files = sorted([p for p in all_imgs if \".c2.\" in p.name.lower() or p.name.lower().endswith(\".c2.png\")])\n",
        "\n",
        "print(f\"Found {len(all_imgs)} total image files\")\n",
        "print(f\"Found {len(c1_files)} C1 images\")\n",
        "print(f\"Found {len(c2_files)} C2 images\")\n",
        "\n",
        "if len(c1_files) == 0 or len(c2_files) == 0:\n",
        "    raise FileNotFoundError(\n",
        "        \"No C1/C2 files detected.\\n\"\n",
        "        \"Expected filenames to contain '.c1.' and '.c2.' (example: t2.1.8.c.c1.png).\"\n",
        "    )\n",
        "\n",
        "# -----------------------\n",
        "# Preview helpers\n",
        "# -----------------------\n",
        "def read_c1_rgb_uint8(path: Path) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Read C1 as RGB uint8 (H,W,3).\n",
        "    This matches the model training assumption: in_channels=3.\n",
        "    \"\"\"\n",
        "    bgr = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "    if bgr is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Handle rare case where image is 16-bit stored in 3 channels (normalize to uint8)\n",
        "    if rgb.dtype == np.uint16:\n",
        "        rgb = (rgb / 256).astype(np.uint8)\n",
        "    elif rgb.dtype != np.uint8:\n",
        "        rgb = cv2.normalize(rgb, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    return rgb\n",
        "\n",
        "def read_c2_gray_uint8(path: Path) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Read C2 as grayscale uint8 (H,W).\n",
        "    \"\"\"\n",
        "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
        "\n",
        "    # Convert to grayscale if needed\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Normalize types\n",
        "    if img.dtype == np.uint16:\n",
        "        img = (img / 256).astype(np.uint8)\n",
        "    elif img.dtype != np.uint8:\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    return img\n",
        "\n",
        "# -----------------------\n",
        "# Show sample images (C1 and C2)\n",
        "# -----------------------\n",
        "sample_c1 = c1_files[0]\n",
        "sample_c2 = c2_files[0]\n",
        "\n",
        "c1_img_rgb = read_c1_rgb_uint8(sample_c1)\n",
        "c2_img = read_c2_gray_uint8(sample_c2)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(c1_img_rgb)\n",
        "plt.title(f\"Sample C1 (RGB): {sample_c1.name}\", fontsize=10)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(c2_img, cmap=\"gray\")\n",
        "plt.title(f\"Sample C2 (grayscale): {sample_c2.name}\", fontsize=10)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0-uUR1e0h7Z",
        "outputId": "17a60203-78d1-4450-837d-2f088b4b94fb"
      },
      "id": "y0-uUR1e0h7Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content/micropillar-precipitation-segmentation\n",
            "INPUT_ROOT: /content/micropillar-precipitation-segmentation/test_images\n",
            "MODEL_DIR: /content/micropillar-precipitation-segmentation/model\n",
            "OUT_ROOT: /content/micropillar-precipitation-segmentation/results\n",
            "\n",
            "Folder check passed.\n",
            "test_images exists: True\n",
            "model exists: True\n",
            "results exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71f5a3e",
      "metadata": {
        "id": "f71f5a3e"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Section 4: Load U-Net model weights (manual Box download + inline upload)\n",
        "# =======================\n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Self-contained device selection\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# Expected model location inside the repo\n",
        "MODEL_PATH = Path(\"model/pillar_unet.pt\")\n",
        "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "BOX_LINK = \"https://cornell.box.com/s/4dyu78bhtpabm98jgz40gdp5wmoe71xn\"\n",
        "\n",
        "# If the model does not exist, require user to download from Box and upload via the Colab button\n",
        "if not MODEL_PATH.exists():\n",
        "    print(\"Model weights are required to run this notebook.\\n\")\n",
        "    print(\"Step A: Download the model file from Box in your browser:\")\n",
        "    print(f\"  {BOX_LINK}\\n\")\n",
        "    print(\"Step B: Upload the downloaded .pt file using the Colab file picker.\\n\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import files  # only available in Colab\n",
        "        uploaded = files.upload()       # user picks the .pt file here\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(\n",
        "            \"Model file is missing, and inline upload is only supported when running in Google Colab.\\n\\n\"\n",
        "            f\"Expected model path:\\n  {MODEL_PATH.resolve()}\\n\\n\"\n",
        "            \"Fix:\\n\"\n",
        "            \"1) Download the .pt file from Box\\n\"\n",
        "            \"2) Upload it into this runtime (Colab recommended)\\n\"\n",
        "            \"3) Re-run this cell\\n\\n\"\n",
        "            f\"Original error:\\n{e}\"\n",
        "        )\n",
        "\n",
        "    # Choose the uploaded .pt file (largest .pt if multiple)\n",
        "    uploaded_pt = [Path(fn) for fn in uploaded.keys() if fn.lower().endswith(\".pt\")]\n",
        "    if len(uploaded_pt) == 0:\n",
        "        raise FileNotFoundError(\n",
        "            \"No .pt file was uploaded.\\n\"\n",
        "            \"Please re-run the cell and upload the model weights file ending in .pt.\"\n",
        "        )\n",
        "\n",
        "    uploaded_pt = sorted(uploaded_pt, key=lambda p: p.stat().st_size, reverse=True)\n",
        "    chosen = uploaded_pt[0]\n",
        "\n",
        "    # Move/rename into repo/model/\n",
        "    chosen.replace(MODEL_PATH)\n",
        "\n",
        "    print(\"\\nModel file saved to:\")\n",
        "    print(f\"  {MODEL_PATH.resolve()}\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"Model file found:\")\n",
        "    print(f\"  {MODEL_PATH.resolve()}\\n\")\n",
        "\n",
        "# -----------------------\n",
        "# Define model architecture (must match training)\n",
        "# -----------------------\n",
        "# IMPORTANT: this checkpoint expects 3-channel input (RGB)\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",\n",
        "    encoder_weights=None,\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        ")\n",
        "\n",
        "# -----------------------\n",
        "# Load checkpoint\n",
        "# -----------------------\n",
        "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\", weights_only=False)\n",
        "state = ckpt[\"state_dict\"] if (isinstance(ckpt, dict) and \"state_dict\" in ckpt) else ckpt\n",
        "\n",
        "# Remove \"model.\" prefix if present\n",
        "clean_state = {}\n",
        "for k, v in state.items():\n",
        "    k2 = k[len(\"model.\"):] if k.startswith(\"model.\") else k\n",
        "    clean_state[k2] = v\n",
        "\n",
        "missing, unexpected = model.load_state_dict(clean_state, strict=False)\n",
        "print(\"Missing keys:\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded and ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f437ff6",
      "metadata": {
        "id": "1f437ff6"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Section 5: Run pillar inference on all images + save outputs + preview a saved result\n",
        "# =======================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Safety: ensure required globals exist\n",
        "if \"INPUT_ROOT\" not in globals():\n",
        "    INPUT_ROOT = Path(\"test_images\")\n",
        "if \"OUT_ROOT\" not in globals():\n",
        "    OUT_ROOT = Path(\"results\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Pairing logic: match by removing \".c1.\" / \".c2.\" token\n",
        "def pair_c1_c2(c1_files, c2_files):\n",
        "    c2_map = {}\n",
        "    for p in c2_files:\n",
        "        key = p.name.replace(\".c2.\", \".\")\n",
        "        c2_map[key] = p\n",
        "\n",
        "    pairs = []\n",
        "    for c1 in c1_files:\n",
        "        key = c1.name.replace(\".c1.\", \".\")\n",
        "        pairs.append((c1, c2_map.get(key)))\n",
        "    return pairs\n",
        "\n",
        "def parse_filename(fname: str):\n",
        "    # Expected example: t2.1.8.c.c1.png\n",
        "    # channel=t2, section=1, diameter=8, trial=c, modality=c1\n",
        "    stem = Path(fname).name\n",
        "    stem = re.sub(r\"\\.(png|jpg|jpeg|tif|tiff)$\", \"\", stem, flags=re.IGNORECASE)\n",
        "    parts = stem.split(\".\")\n",
        "    out = {\"channel\": None, \"section\": None, \"diameter\": None, \"trial\": None, \"modality\": None}\n",
        "\n",
        "    for token in parts[::-1]:\n",
        "        if token.lower() in (\"c1\", \"c2\"):\n",
        "            out[\"modality\"] = token.lower()\n",
        "            break\n",
        "\n",
        "    if len(parts) >= 5:\n",
        "        out[\"channel\"]  = parts[0]\n",
        "        out[\"section\"]  = parts[1]\n",
        "        out[\"diameter\"] = parts[2]\n",
        "        out[\"trial\"]    = parts[3]\n",
        "    return out\n",
        "\n",
        "def save_mask_png(mask01: np.ndarray, out_path: Path) -> None:\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    cv2.imwrite(str(out_path), (mask01.astype(np.uint8) * 255))\n",
        "\n",
        "# Re-discover files from INPUT_ROOT\n",
        "valid_ext = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "all_imgs = sorted([p for p in INPUT_ROOT.rglob(\"*\") if p.suffix.lower() in valid_ext])\n",
        "\n",
        "c1_files = sorted([p for p in all_imgs if \".c1.\" in p.name.lower() or p.name.lower().endswith(\".c1.png\")])\n",
        "c2_files = sorted([p for p in all_imgs if \".c2.\" in p.name.lower() or p.name.lower().endswith(\".c2.png\")])\n",
        "\n",
        "pairs = pair_c1_c2(c1_files, c2_files)\n",
        "\n",
        "MASK_DIR = OUT_ROOT / \"pillar_masks\"\n",
        "MASK_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Using INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"Saving masks to:\", MASK_DIR.resolve())\n",
        "print(\"Pairs to process:\", len(pairs))\n",
        "\n",
        "if len(pairs) == 0:\n",
        "    raise RuntimeError(\"No C1/C2 pairs found. Check test_images filenames.\")\n",
        "\n",
        "mask_index = []\n",
        "\n",
        "for c1_path, c2_path in tqdm(pairs, desc=\"Pillar inference\"):\n",
        "    c1 = read_gray_uint8(c1_path)\n",
        "    mask01 = infer_pillar_mask(c1)\n",
        "\n",
        "    # Save mask with consistent naming: <original>.mask.png\n",
        "    out_mask_path = MASK_DIR / (c1_path.name.replace(\".c1.\", \".c1.\") + \".mask.png\")\n",
        "    out_mask_path = out_mask_path.with_name(c1_path.stem + \".mask.png\")\n",
        "\n",
        "    save_mask_png(mask01, out_mask_path)\n",
        "\n",
        "    meta = parse_filename(c1_path.name)\n",
        "    mask_index.append({\n",
        "        \"c1_path\": str(c1_path),\n",
        "        \"c2_path\": str(c2_path) if c2_path is not None else None,\n",
        "        \"mask_path\": str(out_mask_path),\n",
        "        **meta\n",
        "    })\n",
        "\n",
        "mask_index_df = pd.DataFrame(mask_index)\n",
        "mask_index_csv = OUT_ROOT / \"mask_index.csv\"\n",
        "mask_index_df.to_csv(mask_index_csv, index=False)\n",
        "\n",
        "print(\"Saved mask index:\", mask_index_csv.resolve())\n",
        "print(f\"Saved {len(mask_index_df)} pillar masks\")\n",
        "\n",
        "# Preview a saved result (first one)\n",
        "row0 = mask_index_df.iloc[0]\n",
        "c1_preview = read_gray_uint8(Path(row0[\"c1_path\"]))\n",
        "m_preview  = read_gray_uint8(Path(row0[\"mask_path\"])) > 0\n",
        "\n",
        "overlay = cv2.cvtColor(c1_preview, cv2.COLOR_GRAY2BGR)\n",
        "overlay[m_preview] = (0, 0, 255)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(c1_preview, cmap=\"gray\")\n",
        "plt.title(f\"C1: {Path(row0['c1_path']).name}\", fontsize=10)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"Saved mask overlay: {Path(row0['mask_path']).name}\", fontsize=10)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "mask_index_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Section 4: Load U-Net model weights + preview mask overlays on ALL C1 images (MATCHES OLD PIPELINE)\n",
        "# =======================\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models_pytorch as smp\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# -----------------------\n",
        "# Paths (repo layout)\n",
        "# -----------------------\n",
        "INPUT_ROOT = Path(\"test_images\")\n",
        "MODEL_PATH = Path(\"model/pillar_unet.pt\")\n",
        "BOX_LINK = \"https://cornell.box.com/s/4dyu78bhtpabm98jgz40gdp5wmoe71xn\"\n",
        "\n",
        "if not INPUT_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Missing INPUT_ROOT: {INPUT_ROOT.resolve()}\")\n",
        "\n",
        "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -----------------------\n",
        "# Device\n",
        "# -----------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# -----------------------\n",
        "# If model missing, require inline upload\n",
        "# -----------------------\n",
        "if not MODEL_PATH.exists():\n",
        "    print(\"Model weights are required to run this notebook.\\n\")\n",
        "    print(\"Step A: Download the model file from Box in your browser:\")\n",
        "    print(BOX_LINK)\n",
        "    print(\"\\nStep B: Upload the .pt file using the Colab file picker.\\n\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(\n",
        "            \"Model file is missing, and inline upload is only supported in Google Colab.\\n\\n\"\n",
        "            f\"Expected model path:\\n  {MODEL_PATH.resolve()}\\n\\n\"\n",
        "            \"Fix:\\n\"\n",
        "            \"1) Download the .pt file from Box\\n\"\n",
        "            \"2) Upload it into this runtime\\n\"\n",
        "            \"3) Re-run this cell\\n\\n\"\n",
        "            f\"Original error:\\n{e}\"\n",
        "        )\n",
        "\n",
        "    uploaded_pt = [Path(fn) for fn in uploaded.keys() if fn.lower().endswith(\".pt\")]\n",
        "    if len(uploaded_pt) == 0:\n",
        "        raise FileNotFoundError(\n",
        "            \"No .pt file was uploaded.\\n\"\n",
        "            \"Re-run the cell and upload the model weights file ending in .pt.\"\n",
        "        )\n",
        "\n",
        "    chosen = sorted(uploaded_pt, key=lambda p: p.stat().st_size, reverse=True)[0]\n",
        "    chosen.replace(MODEL_PATH)\n",
        "\n",
        "print(\"MODEL_PATH:\", MODEL_PATH.resolve())\n",
        "\n",
        "# -----------------------\n",
        "# Config\n",
        "# -----------------------\n",
        "VALID_EXT = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "SHORT_SIDE = 768\n",
        "THR = 0.50\n",
        "KERNEL = np.ones((5, 5), np.uint8)\n",
        "\n",
        "def read_rgb_uint8(path: Path) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Read image as RGB uint8 (0..255), preserving true pixel scale.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
        "\n",
        "    if img.dtype == np.uint16:\n",
        "        img = (img / 256).astype(np.uint8)\n",
        "    elif img.dtype != np.uint8:\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    if img.ndim == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    elif img.shape[2] == 4:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def resize_short_rgb(im: np.ndarray, short_side: int = SHORT_SIDE) -> np.ndarray:\n",
        "    h, w = im.shape[:2]\n",
        "    scale = short_side / min(h, w)\n",
        "    new_w = int(round(w * scale))\n",
        "    new_h = int(round(h * scale))\n",
        "    return cv2.resize(im, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# -----------------------\n",
        "# Load checkpoint robustly\n",
        "# -----------------------\n",
        "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\", weights_only=False)\n",
        "state = ckpt[\"state_dict\"] if (isinstance(ckpt, dict) and \"state_dict\" in ckpt) else ckpt\n",
        "\n",
        "clean_state = {}\n",
        "for k, v in state.items():\n",
        "    k2 = k[len(\"model.\"):] if k.startswith(\"model.\") else k\n",
        "    clean_state[k2] = v\n",
        "\n",
        "# -----------------------\n",
        "# Build model as 3-channel (do NOT average conv1)\n",
        "# -----------------------\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",\n",
        "    encoder_weights=None,\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        ")\n",
        "\n",
        "missing, unexpected = model.load_state_dict(clean_state, strict=False)\n",
        "print(\"Missing keys:\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "model.eval()\n",
        "print(\"Model loaded and ready.\")\n",
        "\n",
        "# -----------------------\n",
        "# Inference (MATCHES YOUR OLD WORKING INPUT SCALE)\n",
        "# -----------------------\n",
        "@torch.no_grad()\n",
        "def infer_pillar_mask_from_rgb(rgb_u8: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns 0/1 mask at original resolution.\n",
        "    IMPORTANT: input tensor is float but in 0..255 scale (same as old code).\n",
        "    \"\"\"\n",
        "    H, W = rgb_u8.shape[:2]\n",
        "\n",
        "    rs = resize_short_rgb(rgb_u8, SHORT_SIDE)\n",
        "\n",
        "    # EXACT old behavior:\n",
        "    # ToTensorV2 makes CHW tensor in 0..255 range, then .float()\n",
        "    x_t = ToTensorV2()(image=rs)[\"image\"].unsqueeze(0).to(DEVICE).float()\n",
        "\n",
        "    logits = model(x_t)\n",
        "    prob = torch.sigmoid(logits)[0, 0].detach().cpu().numpy()\n",
        "\n",
        "    prob_full = cv2.resize(prob, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    pred01 = (prob_full > THR).astype(np.uint8)\n",
        "    pred01 = (cv2.morphologyEx(pred01 * 255, cv2.MORPH_OPEN, KERNEL, iterations=1) > 0).astype(np.uint8)\n",
        "    pred01 = (cv2.morphologyEx(pred01 * 255, cv2.MORPH_CLOSE, KERNEL, iterations=1) > 0).astype(np.uint8)\n",
        "\n",
        "    return pred01\n",
        "\n",
        "def overlay_red(rgb_u8: np.ndarray, mask01: np.ndarray, alpha: float = 0.40) -> np.ndarray:\n",
        "    base = rgb_u8.astype(np.float32)\n",
        "    red = np.zeros_like(base)\n",
        "    red[..., 0] = 255.0\n",
        "    m = (mask01 > 0).astype(np.float32)[..., None]\n",
        "    out = base * (1 - alpha * m) + red * (alpha * m)\n",
        "    return np.clip(out, 0, 255).astype(np.uint8)\n",
        "\n",
        "# -----------------------\n",
        "# Discover C1 files\n",
        "# -----------------------\n",
        "all_imgs = sorted([p for p in INPUT_ROOT.rglob(\"*\") if p.suffix.lower() in VALID_EXT])\n",
        "c1_files = sorted([p for p in all_imgs if \".c1.\" in p.name.lower() or p.name.lower().endswith(\".c1.png\")])\n",
        "\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"Total image files found:\", len(all_imgs))\n",
        "print(\"C1 files found:\", len(c1_files))\n",
        "\n",
        "if len(c1_files) == 0:\n",
        "    raise FileNotFoundError(\"No C1 images found. Expected names like: t2.1.8.c.c1.png\")\n",
        "\n",
        "# -----------------------\n",
        "# Show overlay for ALL C1 images\n",
        "# -----------------------\n",
        "overlays = []\n",
        "titles = []\n",
        "\n",
        "for p in c1_files:\n",
        "    rgb = read_rgb_uint8(p)\n",
        "    mask01 = infer_pillar_mask_from_rgb(rgb)\n",
        "    cov = 100.0 * mask01.mean()\n",
        "    overlays.append(overlay_red(rgb, mask01, alpha=0.40))\n",
        "    titles.append(f\"{p.name}\\nmask={cov:.1f}%\")\n",
        "\n",
        "cols = 3\n",
        "rows = int(np.ceil(len(overlays) / cols))\n",
        "\n",
        "plt.figure(figsize=(6 * cols, 6 * rows))\n",
        "for i, (img, t) in enumerate(zip(overlays, titles), start=1):\n",
        "    plt.subplot(rows, cols, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(t, fontsize=10)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lPqPCTC-DFec"
      },
      "id": "lPqPCTC-DFec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91b72a0",
      "metadata": {
        "id": "d91b72a0"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Section 6: Save pillar masks for ALL C1 images (writes results/pillar_masks + results/mask_index.csv)\n",
        "# =======================\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# -----------------------\n",
        "# Paths (repo layout)\n",
        "# -----------------------\n",
        "INPUT_ROOT = Path(\"test_images\")\n",
        "OUT_ROOT   = Path(\"results\")\n",
        "MASK_ROOT  = OUT_ROOT / \"pillar_masks\"\n",
        "INDEX_CSV  = OUT_ROOT / \"mask_index.csv\"\n",
        "\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "MASK_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not INPUT_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Missing INPUT_ROOT: {INPUT_ROOT.resolve()}\")\n",
        "\n",
        "# -----------------------\n",
        "# Require model from Section 4\n",
        "# -----------------------\n",
        "if \"model\" not in globals():\n",
        "    raise NameError(\"Model not found in globals. Run Section 4 first to load the U-Net model.\")\n",
        "if \"DEVICE\" not in globals():\n",
        "    DEVICE = \"cuda\" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else \"cpu\"\n",
        "\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"MASK_ROOT:\", MASK_ROOT.resolve())\n",
        "print(\"INDEX_CSV:\", INDEX_CSV.resolve())\n",
        "print(\"Using DEVICE:\", DEVICE)\n",
        "\n",
        "# -----------------------\n",
        "# Config (match your old inference style)\n",
        "# -----------------------\n",
        "SHORT_SIDE = 768\n",
        "THR = 0.50\n",
        "OVERWRITE = True   # set False if you want to keep existing masks\n",
        "\n",
        "KERNEL = np.ones((5, 5), np.uint8)\n",
        "VALID_EXT = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "\n",
        "def resize_short(im: np.ndarray, short: int = SHORT_SIDE) -> np.ndarray:\n",
        "    \"\"\"Resize image so min(H,W) == short while preserving aspect ratio.\"\"\"\n",
        "    h, w = im.shape[:2]\n",
        "    s = short / min(h, w)\n",
        "    return cv2.resize(im, (int(round(w * s)), int(round(h * s))), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def read_rgb_uint8(img_path: Path) -> np.ndarray:\n",
        "    \"\"\"Read image as RGB uint8 (H,W,3).\"\"\"\n",
        "    bgr = cv2.imread(str(img_path), cv2.IMREAD_UNCHANGED)\n",
        "    if bgr is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {img_path}\")\n",
        "\n",
        "    # If grayscale, convert to 3-channel\n",
        "    if bgr.ndim == 2:\n",
        "        bgr = cv2.cvtColor(bgr, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # If 16-bit, downscale\n",
        "    if bgr.dtype == np.uint16:\n",
        "        bgr = (bgr / 256).astype(np.uint8)\n",
        "    elif bgr.dtype != np.uint8:\n",
        "        bgr = cv2.normalize(bgr, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "    return rgb\n",
        "\n",
        "def find_matching_c2(c1_path: Path) -> Path | None:\n",
        "    \"\"\"Match C2 by swapping '.c1.' -> '.c2.' in filename (same folder).\"\"\"\n",
        "    name = c1_path.name\n",
        "    name2 = name.lower()\n",
        "    if \".c1.\" in name2:\n",
        "        c2_name = re.sub(r\"\\.c1\\.\", \".c2.\", name, flags=re.IGNORECASE)\n",
        "        c2_path = c1_path.with_name(c2_name)\n",
        "        return c2_path if c2_path.exists() else None\n",
        "    return None\n",
        "\n",
        "# albumentations ToTensorV2 import (same as your old pipeline)\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer_mask01_from_rgb(rgb_uint8: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Run U-Net, return mask01 uint8 {0,1} at original resolution.\n",
        "    IMPORTANT: uses your old pipeline:\n",
        "      RGB -> resize_short -> ToTensorV2 -> sigmoid -> resize back -> thr -> morph\n",
        "    \"\"\"\n",
        "    H, W = rgb_uint8.shape[:2]\n",
        "\n",
        "    rs = resize_short(rgb_uint8, SHORT_SIDE)\n",
        "    ten = ToTensorV2()(image=rs)[\"image\"].unsqueeze(0).to(DEVICE).float()\n",
        "\n",
        "    prob = torch.sigmoid(model(ten))[0, 0].detach().cpu().numpy()\n",
        "    prob_full = cv2.resize(prob, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    mask01 = (prob_full > THR).astype(np.uint8)\n",
        "\n",
        "    # morph clean (on 0/255)\n",
        "    m255 = mask01 * 255\n",
        "    m255 = cv2.morphologyEx(m255, cv2.MORPH_OPEN,  KERNEL, iterations=1)\n",
        "    m255 = cv2.morphologyEx(m255, cv2.MORPH_CLOSE, KERNEL, iterations=1)\n",
        "    mask01 = (m255 > 0).astype(np.uint8)\n",
        "    return mask01\n",
        "\n",
        "def save_mask(mask01: np.ndarray, out_path: Path) -> None:\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    cv2.imwrite(str(out_path), (mask01.astype(np.uint8) * 255))\n",
        "\n",
        "# -----------------------\n",
        "# Discover files\n",
        "# -----------------------\n",
        "all_imgs = sorted([p for p in INPUT_ROOT.rglob(\"*\") if p.suffix.lower() in VALID_EXT])\n",
        "c1_files = sorted([p for p in all_imgs if \".c1.\" in p.name.lower() or p.name.lower().endswith(\".c1.png\")])\n",
        "\n",
        "print(\"Total image files found:\", len(all_imgs))\n",
        "print(\"Total C1 found:\", len(c1_files))\n",
        "\n",
        "if len(c1_files) == 0:\n",
        "    raise FileNotFoundError(\n",
        "        f\"No C1 images found under {INPUT_ROOT.resolve()}.\\n\"\n",
        "        \"Expected filenames like: t2.1.8.c.c1.png\"\n",
        "    )\n",
        "\n",
        "# -----------------------\n",
        "# Run inference + save masks + write index CSV\n",
        "# -----------------------\n",
        "rows = []\n",
        "saved = 0\n",
        "skipped = 0\n",
        "\n",
        "for c1_path in tqdm(c1_files, desc=\"Saving pillar masks\"):\n",
        "    c2_path = find_matching_c2(c1_path)\n",
        "\n",
        "    out_mask_path = MASK_ROOT / f\"{c1_path.stem}.mask.png\"\n",
        "\n",
        "    if out_mask_path.exists() and not OVERWRITE:\n",
        "        skipped += 1\n",
        "        rows.append({\n",
        "            \"c1_path\": str(c1_path),\n",
        "            \"c2_path\": str(c2_path) if c2_path is not None else None,\n",
        "            \"mask_path\": str(out_mask_path),\n",
        "            \"threshold\": THR\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    rgb = read_rgb_uint8(c1_path)\n",
        "    mask01 = infer_mask01_from_rgb(rgb)\n",
        "\n",
        "    save_mask(mask01, out_mask_path)\n",
        "    saved += 1\n",
        "\n",
        "    rows.append({\n",
        "        \"c1_path\": str(c1_path),\n",
        "        \"c2_path\": str(c2_path) if c2_path is not None else None,\n",
        "        \"mask_path\": str(out_mask_path),\n",
        "        \"threshold\": THR\n",
        "    })\n",
        "\n",
        "df_index = pd.DataFrame(rows)\n",
        "df_index.to_csv(INDEX_CSV, index=False)\n",
        "\n",
        "print(\"\\nSaved masks:\", saved)\n",
        "print(\"Skipped (already existed):\", skipped)\n",
        "print(\"Wrote:\", INDEX_CSV.resolve())\n",
        "\n",
        "# -----------------------\n",
        "# Quick sanity preview: show ONE saved overlay (mask on raw)\n",
        "# -----------------------\n",
        "row0 = df_index.iloc[0]\n",
        "c1p = Path(row0[\"c1_path\"])\n",
        "mp  = Path(row0[\"mask_path\"])\n",
        "\n",
        "rgb0 = read_rgb_uint8(c1p)\n",
        "m01  = (cv2.imread(str(mp), cv2.IMREAD_GRAYSCALE) > 0).astype(np.uint8)\n",
        "\n",
        "overlay = rgb0.copy()\n",
        "overlay[m01 > 0] = (255, 0, 0)  # red fill in RGB\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"{c1p.name}  (saved: {mp.name})\", fontsize=10)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db0d4f8",
      "metadata": {
        "id": "0db0d4f8"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Section 7: Storyboard (random example) with matched C1 + saved pillar mask + C2 processing + metrics\n",
        "# =======================\n",
        "\n",
        "import os, glob, random, re\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------\n",
        "# Paths (repo layout)\n",
        "# -----------------------\n",
        "INPUT_ROOT = Path(\"test_images\")\n",
        "OUT_ROOT   = Path(\"results\")\n",
        "MASK_ROOT  = OUT_ROOT / \"pillar_masks\"\n",
        "\n",
        "if not INPUT_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Missing INPUT_ROOT: {INPUT_ROOT.resolve()}\")\n",
        "if not MASK_ROOT.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing MASK_ROOT: {MASK_ROOT.resolve()}\\n\\n\"\n",
        "        \"Fix: Run Section 6 first to save pillar masks into results/pillar_masks/\"\n",
        "    )\n",
        "\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"MASK_ROOT:\", MASK_ROOT.resolve())\n",
        "\n",
        "# -----------------------\n",
        "# Imaging scale (same as your old storyboard)\n",
        "# -----------------------\n",
        "FIELD_UM   = 1331.2\n",
        "IMG_PX     = 2048\n",
        "um_per_px  = FIELD_UM / IMG_PX\n",
        "\n",
        "# -----------------------\n",
        "# Scale bar style\n",
        "# -----------------------\n",
        "SCALE_UM      = 500\n",
        "BAR_THICK_PX  = 35\n",
        "MARGIN_PX     = 100\n",
        "FONT          = cv2.FONT_HERSHEY_SIMPLEX\n",
        "FONT_SCALE    = 4\n",
        "FONT_THICK    = 13\n",
        "\n",
        "# -----------------------\n",
        "# C2 binarization settings (same as old)\n",
        "# -----------------------\n",
        "# Choose ONE mode: \"percentile\", \"fixed\", \"otsu+\"\n",
        "C2_THRESH_MODE = \"fixed\"\n",
        "C2_FIXED       = 130\n",
        "C2_PERCENTILE  = 94\n",
        "C2_DELTA       = 15\n",
        "\n",
        "# -----------------------\n",
        "# Helpers\n",
        "# -----------------------\n",
        "VALID_EXT = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "\n",
        "def is_img_path(p: Path) -> bool:\n",
        "    return p.suffix.lower() in VALID_EXT\n",
        "\n",
        "def read_gray_uint8(path: Path) -> np.ndarray:\n",
        "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    if img.dtype == np.uint16:\n",
        "        img = (img / 256).astype(np.uint8)\n",
        "    elif img.dtype != np.uint8:\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def add_scale_bar(gray_img, um_per_px, scale_um=SCALE_UM,\n",
        "                  bar_thick_px=BAR_THICK_PX, margin_px=MARGIN_PX):\n",
        "    rgb = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n",
        "    h, w = gray_img.shape[:2]\n",
        "    bar_len_px = int(round(scale_um / um_per_px))\n",
        "    bar_len_px = min(bar_len_px, w - 2 * margin_px - 1)\n",
        "\n",
        "    x2 = w - margin_px\n",
        "    x1 = x2 - bar_len_px\n",
        "    y2 = h - margin_px\n",
        "    y1 = y2 - bar_thick_px\n",
        "\n",
        "    outline_pad = 2\n",
        "    cv2.rectangle(rgb, (x1 - outline_pad, y1 - outline_pad),\n",
        "                  (x2 + outline_pad, y2 + outline_pad), (0, 0, 0), -1)\n",
        "    cv2.rectangle(rgb, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
        "\n",
        "    label = f\"{scale_um:.0f} um\"\n",
        "    (tw, th), _ = cv2.getTextSize(label, FONT, FONT_SCALE, FONT_THICK)\n",
        "    tx = x1 + (bar_len_px - tw) // 2\n",
        "    ty = y1 - 8\n",
        "\n",
        "    cv2.putText(rgb, label, (tx, ty), FONT, FONT_SCALE, (0, 0, 0),\n",
        "                FONT_THICK + 2, cv2.LINE_AA)\n",
        "    cv2.putText(rgb, label, (tx, ty), FONT, FONT_SCALE, (255, 255, 255),\n",
        "                FONT_THICK, cv2.LINE_AA)\n",
        "    return rgb\n",
        "\n",
        "def find_matching_c2(c1_path: Path) -> Path | None:\n",
        "    name = c1_path.name\n",
        "    if re.search(r\"\\.c1\\.\", name, flags=re.IGNORECASE):\n",
        "        c2_name = re.sub(r\"\\.c1\\.\", \".c2.\", name, flags=re.IGNORECASE)\n",
        "        c2_path = c1_path.with_name(c2_name)\n",
        "        return c2_path if c2_path.exists() else None\n",
        "    return None\n",
        "\n",
        "def mask_path_for_c1(c1_path: Path) -> Path:\n",
        "    # Section 6 naming: results/pillar_masks/<c1_stem>.mask.png\n",
        "    return MASK_ROOT / f\"{c1_path.stem}.mask.png\"\n",
        "\n",
        "def to_u8(img: np.ndarray) -> np.ndarray:\n",
        "    if img.dtype == np.uint8:\n",
        "        return img\n",
        "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "def binarize_c2(C2_raw: np.ndarray, nonpillar_mask01: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return binary crystal mask (uint8 0/255), conservative thresholding.\n",
        "    nonpillar_mask01 is uint8 {0,1}.\n",
        "    \"\"\"\n",
        "    img = to_u8(C2_raw)\n",
        "    roi = cv2.bitwise_and(img, img, mask=(nonpillar_mask01 * 255))\n",
        "    blur = cv2.GaussianBlur(roi, (3, 3), 0)\n",
        "\n",
        "    if C2_THRESH_MODE == \"fixed\":\n",
        "        thr_val = int(C2_FIXED)\n",
        "        _, thr = cv2.threshold(blur, thr_val, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    elif C2_THRESH_MODE == \"percentile\":\n",
        "        vals = blur[nonpillar_mask01 > 0]\n",
        "        thr_val = int(np.percentile(vals, C2_PERCENTILE)) if vals.size else 255\n",
        "        _, thr = cv2.threshold(blur, thr_val, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    else:  # \"otsu+\"\n",
        "        t0, _ = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        thr_val = int(max(0, min(255, t0 + C2_DELTA)))\n",
        "        _, thr = cv2.threshold(blur, thr_val, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    thr[nonpillar_mask01 == 0] = 0\n",
        "    k = np.ones((3, 3), np.uint8)\n",
        "    thr = cv2.morphologyEx(thr, cv2.MORPH_OPEN,  k, iterations=1)\n",
        "    thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, k, iterations=1)\n",
        "    return thr\n",
        "\n",
        "# -----------------------\n",
        "# Pick a random VALID triplet (C1 + C2 + saved mask)\n",
        "# -----------------------\n",
        "all_imgs = sorted([p for p in INPUT_ROOT.rglob(\"*\") if is_img_path(p)])\n",
        "c1_files = sorted([p for p in all_imgs if \".c1.\" in p.name.lower() or p.name.lower().endswith(\".c1.png\")])\n",
        "\n",
        "triplets = []\n",
        "for c1 in c1_files:\n",
        "    c2 = find_matching_c2(c1)\n",
        "    mp = mask_path_for_c1(c1)\n",
        "    if (c2 is not None) and mp.exists():\n",
        "        triplets.append((c1, c2, mp))\n",
        "\n",
        "print(\"Total C1 found:\", len(c1_files))\n",
        "print(\"Triplets with C2 + saved mask:\", len(triplets))\n",
        "\n",
        "if len(triplets) == 0:\n",
        "    example_missing = []\n",
        "    for c1 in c1_files[:5]:\n",
        "        c2 = find_matching_c2(c1)\n",
        "        mp = mask_path_for_c1(c1)\n",
        "        example_missing.append((c1.name, mp.exists(), c2 is not None))\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find any (C1, C2, saved mask) triplets.\\n\\n\"\n",
        "        \"Expected:\\n\"\n",
        "        \"  - C2 exists for each C1 (same name except .c2.)\\n\"\n",
        "        \"  - mask exists at: results/pillar_masks/<c1_stem>.mask.png\\n\\n\"\n",
        "        f\"Examples (c1_name, mask_exists, c2_exists):\\n  {example_missing}\\n\\n\"\n",
        "        \"Fix:\\n\"\n",
        "        \"  1) Run Section 6 to save masks\\n\"\n",
        "        \"  2) Ensure masks were written to results/pillar_masks/\"\n",
        "    )\n",
        "\n",
        "c1_path, c2_path, mask_path = random.choice(triplets)\n",
        "print(\"\\nStoryboard example:\")\n",
        "print(\"  C1:\", c1_path.name)\n",
        "print(\"  C2:\", c2_path.name)\n",
        "print(\"  MASK:\", mask_path.name)\n",
        "\n",
        "# -----------------------\n",
        "# Load images\n",
        "# -----------------------\n",
        "C1_raw  = read_gray_uint8(c1_path)\n",
        "C2_raw  = read_gray_uint8(c2_path)\n",
        "C1_mask = read_gray_uint8(mask_path)\n",
        "\n",
        "# Ensure mask is aligned\n",
        "if C1_mask.shape != C2_raw.shape:\n",
        "    C1_mask = cv2.resize(C1_mask, (C2_raw.shape[1], C2_raw.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "pillar01   = (C1_mask > 0).astype(np.uint8)\n",
        "nonpillar01 = (pillar01 == 0).astype(np.uint8)\n",
        "\n",
        "# -----------------------\n",
        "# Metrics: pillar vs non-pillar\n",
        "# -----------------------\n",
        "total_pixels     = int(pillar01.size)\n",
        "pillar_pixels    = int((pillar01 > 0).sum())\n",
        "nonpillar_pixels = total_pixels - pillar_pixels\n",
        "pillar_pct       = 100.0 * pillar_pixels / total_pixels\n",
        "nonpillar_pct    = 100.0 * nonpillar_pixels / total_pixels\n",
        "\n",
        "# -----------------------\n",
        "# C2 processing\n",
        "# -----------------------\n",
        "precip = binarize_c2(C2_raw, nonpillar01)\n",
        "\n",
        "crystal_pixels           = int((precip > 0).sum())\n",
        "crystal_pct              = 100.0 * crystal_pixels / total_pixels\n",
        "crystal_in_nonpillar_pct = 100.0 * crystal_pixels / max(1, nonpillar_pixels)\n",
        "\n",
        "# -----------------------\n",
        "# Overlays\n",
        "# -----------------------\n",
        "proc_rgb = cv2.cvtColor(to_u8(C2_raw), cv2.COLOR_GRAY2RGB)\n",
        "proc_rgb[precip > 0] = (255, 0, 0)       # crystals red\n",
        "proc_rgb[pillar01 > 0] = (0, 0, 0)       # pillars black for contrast\n",
        "\n",
        "overlay = np.zeros_like(proc_rgb)\n",
        "contours, _ = cv2.findContours((pillar01 > 0).astype(np.uint8),\n",
        "                               cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cv2.drawContours(overlay, contours, -1, (255, 255, 0), 2)  # yellow outlines\n",
        "proc_with_outline = cv2.addWeighted(proc_rgb, 1.0, overlay, 1.0, 0)\n",
        "\n",
        "final_rgb = np.zeros_like(proc_rgb)\n",
        "final_rgb[pillar01 > 0] = (0, 0, 0)\n",
        "final_rgb[nonpillar01 > 0] = (255, 255, 255)\n",
        "final_rgb[precip > 0] = (255, 0, 0)\n",
        "\n",
        "# -----------------------\n",
        "# Add scale bars to raw views\n",
        "# -----------------------\n",
        "C1_with_bar = add_scale_bar(to_u8(C1_raw), um_per_px, SCALE_UM)\n",
        "C2_with_bar = add_scale_bar(to_u8(C2_raw), um_per_px, SCALE_UM)\n",
        "\n",
        "# -----------------------\n",
        "# Plot storyboard\n",
        "# -----------------------\n",
        "fig, axes = plt.subplots(1, 5, figsize=(22, 5))\n",
        "\n",
        "axes[0].imshow(C1_with_bar)\n",
        "axes[0].set_title(\"C1 Brightfield (raw + scale bar)\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(pillar01 * 255, cmap=\"gray\")\n",
        "axes[1].set_title(f\"Pillar mask\\nNon-pillar: {nonpillar_pct:.1f}%\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].imshow(C2_with_bar)\n",
        "axes[2].set_title(\"C2 TL-POL (raw + scale bar)\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "axes[3].imshow(proc_with_outline)\n",
        "axes[3].set_title(\"C2 processed\\n+ pillar outlines\")\n",
        "axes[3].axis(\"off\")\n",
        "\n",
        "axes[4].imshow(final_rgb)\n",
        "axes[4].set_title(\n",
        "    \"Final composite\\n\"\n",
        "    f\"Pillar: {pillar_pct:.1f}% | Non-pillar: {nonpillar_pct:.1f}%\\n\"\n",
        "    f\"Crystal: {crystal_pct:.1f}% | Crystal/Non-pillar: {crystal_in_nonpillar_pct:.1f}%\"\n",
        ")\n",
        "axes[4].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\n",
        "    f\"{c1_path.stem} | {C1_raw.shape[1]}Ã—{C1_raw.shape[0]} px | \"\n",
        "    f\"{FIELD_UM:.1f} Âµm FOV (~{um_per_px:.2f} Âµm/px)\",\n",
        "    fontsize=14,\n",
        "    fontweight=\"bold\"\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# Section 7: Build storyboards for ALL images (C1 + mask + C2 processing) + save + preview ALL\n",
        "# =======================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------\n",
        "# Paths (GitHub repo layout)\n",
        "# -----------------------\n",
        "INPUT_ROOT = Path(\"test_images\")\n",
        "OUT_ROOT   = Path(\"results\")\n",
        "MASK_ROOT  = OUT_ROOT / \"pillar_masks\"\n",
        "STORY_DIR  = OUT_ROOT / \"storyboards\"\n",
        "\n",
        "if not INPUT_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Missing input folder: {INPUT_ROOT.resolve()}\")\n",
        "if not MASK_ROOT.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing mask folder: {MASK_ROOT.resolve()}\\n\"\n",
        "        \"Run Section 6 first to generate pillar masks.\"\n",
        "    )\n",
        "\n",
        "STORY_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"INPUT_ROOT:\", INPUT_ROOT.resolve())\n",
        "print(\"MASK_ROOT:\", MASK_ROOT.resolve())\n",
        "print(\"Saving storyboards to:\", STORY_DIR.resolve())\n",
        "\n",
        "# -----------------------\n",
        "# Imaging scale\n",
        "# -----------------------\n",
        "FIELD_UM = 1331.2   # field of view (Âµm)\n",
        "IMG_PX   = 2048     # pixels per side\n",
        "um_per_px = FIELD_UM / IMG_PX\n",
        "\n",
        "# -----------------------\n",
        "# Scale bar style\n",
        "# -----------------------\n",
        "SCALE_UM     = 500\n",
        "BAR_THICK_PX = 35\n",
        "MARGIN_PX    = 100\n",
        "FONT         = cv2.FONT_HERSHEY_SIMPLEX\n",
        "FONT_SCALE   = 1.2\n",
        "FONT_THICK   = 3\n",
        "\n",
        "# -----------------------\n",
        "# C2 binarization settings\n",
        "# -----------------------\n",
        "# Choose ONE:\n",
        "#   \"fixed\"       : use C2_FIXED\n",
        "#   \"percentile\"  : use C2_PERCENTILE\n",
        "#   \"otsu+\"       : use Otsu + C2_DELTA\n",
        "C2_THRESH_MODE = \"fixed\"\n",
        "\n",
        "# If C2_THRESH_MODE == \"fixed\":\n",
        "C2_FIXED = 140\n",
        "\n",
        "# If C2_THRESH_MODE == \"percentile\":\n",
        "C2_PERCENTILE = 94\n",
        "\n",
        "# If C2_THRESH_MODE == \"otsu+\":\n",
        "C2_DELTA = 15\n",
        "\n",
        "# Morphology cleanup for C2 precip\n",
        "C2_MORPH_KERNEL = np.ones((3, 3), np.uint8)\n",
        "\n",
        "VALID_EXT = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
        "\n",
        "# -----------------------\n",
        "# Helpers\n",
        "# -----------------------\n",
        "def read_gray_uint8(path: Path) -> np.ndarray:\n",
        "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    if img.dtype == np.uint16:\n",
        "        img = (img / 256).astype(np.uint8)\n",
        "    elif img.dtype != np.uint8:\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def add_scale_bar(gray_img: np.ndarray, um_per_px: float, scale_um: float = SCALE_UM) -> np.ndarray:\n",
        "    \"\"\"Return RGB copy of gray_img with a scale bar.\"\"\"\n",
        "    rgb = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n",
        "    h, w = gray_img.shape[:2]\n",
        "\n",
        "    bar_len_px = int(round(scale_um / um_per_px))\n",
        "    bar_len_px = min(bar_len_px, w - 2 * MARGIN_PX - 1)\n",
        "\n",
        "    x2 = w - MARGIN_PX\n",
        "    x1 = x2 - bar_len_px\n",
        "    y2 = h - MARGIN_PX\n",
        "    y1 = y2 - BAR_THICK_PX\n",
        "\n",
        "    outline_pad = 2\n",
        "    cv2.rectangle(\n",
        "        rgb,\n",
        "        (x1 - outline_pad, y1 - outline_pad),\n",
        "        (x2 + outline_pad, y2 + outline_pad),\n",
        "        (0, 0, 0),\n",
        "        -1\n",
        "    )\n",
        "    cv2.rectangle(rgb, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
        "\n",
        "    label = f\"{scale_um:.0f} um\"\n",
        "    (tw, th), _ = cv2.getTextSize(label, FONT, FONT_SCALE, FONT_THICK)\n",
        "    tx = x1 + (bar_len_px - tw) // 2\n",
        "    ty = y1 - 10\n",
        "    ty = max(20, ty)\n",
        "\n",
        "    cv2.putText(rgb, label, (tx, ty), FONT, FONT_SCALE, (0, 0, 0), FONT_THICK + 2, cv2.LINE_AA)\n",
        "    cv2.putText(rgb, label, (tx, ty), FONT, FONT_SCALE, (255, 255, 255), FONT_THICK, cv2.LINE_AA)\n",
        "    return rgb\n",
        "\n",
        "def to_u8(img: np.ndarray) -> np.ndarray:\n",
        "    if img.dtype == np.uint8:\n",
        "        return img\n",
        "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "def binarize_c2(C2_raw: np.ndarray, nonpillar_mask01: np.ndarray) -> tuple[np.ndarray, int]:\n",
        "    \"\"\"\n",
        "    Conservative C2 thresholding restricted to non-pillar region.\n",
        "    Returns:\n",
        "      thr_mask (uint8 0/255),\n",
        "      thr_value (int)\n",
        "    \"\"\"\n",
        "    img = to_u8(C2_raw)\n",
        "\n",
        "    roi = cv2.bitwise_and(img, img, mask=(nonpillar_mask01.astype(np.uint8) * 255))\n",
        "    blur = cv2.GaussianBlur(roi, (3, 3), 0)\n",
        "\n",
        "    if C2_THRESH_MODE == \"fixed\":\n",
        "        thr_val = int(C2_FIXED)\n",
        "        _, thr = cv2.threshold(blur, thr_val, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    elif C2_THRESH_MODE == \"percentile\":\n",
        "        vals = blur[nonpillar_mask01 > 0]\n",
        "        thr_val = int(np.percentile(vals, C2_PERCENTILE)) if vals.size else 255\n",
        "        _, thr = cv2.threshold(blur, thr_val, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    else:  # \"otsu+\"\n",
        "        t0, _ = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        thr_val = int(max(0, min(255, int(t0) + int(C2_DELTA))))\n",
        "        _, thr = cv2.threshold(blur, thr_val, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    thr[nonpillar_mask01 == 0] = 0\n",
        "    thr = cv2.morphologyEx(thr, cv2.MORPH_OPEN, C2_MORPH_KERNEL, iterations=1)\n",
        "    thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, C2_MORPH_KERNEL, iterations=1)\n",
        "\n",
        "    return thr, thr_val\n",
        "\n",
        "def find_matching_c2(c1_path: Path) -> Path | None:\n",
        "    \"\"\"\n",
        "    Match t2.1.8.c.c1.png -> t2.1.8.c.c2.png\n",
        "    \"\"\"\n",
        "    name = c1_path.name\n",
        "    c2_name = name.replace(\".c1.\", \".c2.\")\n",
        "    if c2_name == name:\n",
        "        # fallback: if unexpected, just try stem replacement\n",
        "        c2_name = c1_path.stem.replace(\".c1\", \".c2\") + c1_path.suffix\n",
        "\n",
        "    candidate = c1_path.with_name(c2_name)\n",
        "    return candidate if candidate.exists() else None\n",
        "\n",
        "def mask_path_for_c1(c1_path: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Section 6 saved masks as:\n",
        "      results/pillar_masks/<c1_stem>.mask.png\n",
        "    Example:\n",
        "      t2.1.8.c.c1.png -> t2.1.8.c.c1.mask.png\n",
        "    \"\"\"\n",
        "    return MASK_ROOT / f\"{c1_path.stem}.mask.png\"\n",
        "\n",
        "# -----------------------\n",
        "# Discover images\n",
        "# -----------------------\n",
        "all_imgs = sorted([p for p in INPUT_ROOT.rglob(\"*\") if p.suffix.lower() in VALID_EXT])\n",
        "\n",
        "c1_files = sorted([p for p in all_imgs if \".c1.\" in p.name.lower() or p.name.lower().endswith(\".c1.png\")])\n",
        "print(\"Total C1 found:\", len(c1_files))\n",
        "\n",
        "if len(c1_files) == 0:\n",
        "    raise FileNotFoundError(\"No C1 images found. Expected names like: t2.1.8.c.c1.png\")\n",
        "\n",
        "# -----------------------\n",
        "# Build (C1, C2, mask) triplets\n",
        "# -----------------------\n",
        "triplets = []\n",
        "missing_masks = []\n",
        "missing_c2 = []\n",
        "\n",
        "for c1 in c1_files:\n",
        "    c2 = find_matching_c2(c1)\n",
        "    mpath = mask_path_for_c1(c1)\n",
        "\n",
        "    if c2 is None:\n",
        "        missing_c2.append(c1.name)\n",
        "        continue\n",
        "    if not mpath.exists():\n",
        "        missing_masks.append(c1.name)\n",
        "        continue\n",
        "\n",
        "    triplets.append((c1, c2, mpath))\n",
        "\n",
        "print(\"Triplets with C2 + saved mask:\", len(triplets))\n",
        "\n",
        "if len(triplets) == 0:\n",
        "    example_missing = []\n",
        "    for c1 in c1_files[:10]:\n",
        "        example_missing.append((c1.name, str(mask_path_for_c1(c1).exists()), str(find_matching_c2(c1) is not None)))\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find any (C1, C2, mask) triplets.\\n\\n\"\n",
        "        \"Expected:\\n\"\n",
        "        \"  - C2 exists for each C1 (same name except .c2.)\\n\"\n",
        "        \"  - mask exists at: results/pillar_masks/<c1_stem>.mask.png\\n\\n\"\n",
        "        \"Examples (C1 name, mask_exists, c2_exists):\\n\"\n",
        "        f\"  {example_missing}\\n\\n\"\n",
        "        \"Fix:\\n\"\n",
        "        \"  1) Re-run Section 6 to generate masks\\n\"\n",
        "        \"  2) Confirm mask naming is <c1_stem>.mask.png\"\n",
        "    )\n",
        "\n",
        "# -----------------------\n",
        "# Build storyboards + metrics for ALL triplets\n",
        "# -----------------------\n",
        "metrics_rows = []\n",
        "\n",
        "for c1_path, c2_path, mask_path in triplets:\n",
        "    base_key = c1_path.stem.replace(\".c1\", \"\")\n",
        "\n",
        "    # Load raw images + mask\n",
        "    C1_raw = read_gray_uint8(c1_path)\n",
        "    C2_raw = read_gray_uint8(c2_path)\n",
        "\n",
        "    C1_mask = read_gray_uint8(mask_path)\n",
        "    if C1_mask.shape != C2_raw.shape:\n",
        "        C1_mask = cv2.resize(C1_mask, (C2_raw.shape[1], C2_raw.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    pillar01 = (C1_mask > 0).astype(np.uint8)\n",
        "    nonpillar01 = (pillar01 == 0).astype(np.uint8)\n",
        "\n",
        "    # Metrics: pillar vs nonpillar\n",
        "    total_pixels = int(C1_mask.size)\n",
        "    pillar_pixels = int(pillar01.sum())\n",
        "    nonpillar_pixels = int(total_pixels - pillar_pixels)\n",
        "\n",
        "    pillar_pct = 100.0 * pillar_pixels / max(1, total_pixels)\n",
        "    nonpillar_pct = 100.0 * nonpillar_pixels / max(1, total_pixels)\n",
        "\n",
        "    # C2 precipitation mask (restricted to nonpillar)\n",
        "    precip255, thr_val = binarize_c2(C2_raw, nonpillar01)\n",
        "    precip01 = (precip255 > 0).astype(np.uint8)\n",
        "\n",
        "    crystal_pixels = int(precip01.sum())\n",
        "    crystal_pct_total = 100.0 * crystal_pixels / max(1, total_pixels)\n",
        "    crystal_pct_nonpillar = 100.0 * crystal_pixels / max(1, nonpillar_pixels)\n",
        "\n",
        "    # Overlays\n",
        "    proc_rgb = cv2.cvtColor(C2_raw, cv2.COLOR_GRAY2RGB)\n",
        "    proc_rgb[precip01 > 0] = (255, 0, 0)     # crystals red\n",
        "    proc_rgb[pillar01 > 0] = (0, 0, 0)       # pillars black\n",
        "\n",
        "    overlay = np.zeros_like(proc_rgb)\n",
        "    contours, _ = cv2.findContours(pillar01, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(overlay, contours, -1, (255, 255, 0), 2)  # pillar outlines yellow\n",
        "    proc_with_outline = cv2.addWeighted(proc_rgb, 1.0, overlay, 1.0, 0)\n",
        "\n",
        "    final_rgb = np.zeros_like(proc_rgb)\n",
        "    final_rgb[pillar01 > 0] = (0, 0, 0)          # pillars\n",
        "    final_rgb[nonpillar01 > 0] = (255, 255, 255) # background\n",
        "    final_rgb[precip01 > 0] = (255, 0, 0)        # crystals\n",
        "\n",
        "    # Add scale bars\n",
        "    C1_with_bar = add_scale_bar(C1_raw, um_per_px, SCALE_UM)\n",
        "    C2_with_bar = add_scale_bar(C2_raw, um_per_px, SCALE_UM)\n",
        "\n",
        "    # Plot storyboard\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(22, 5))\n",
        "\n",
        "    axes[0].imshow(C1_with_bar)\n",
        "    axes[0].set_title(\"C1 Brightfield (raw + scale bar)\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(pillar01 * 255, cmap=\"gray\")\n",
        "    axes[1].set_title(f\"Pillar Mask\\nNon-pillar: {nonpillar_pct:.1f}%\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    axes[2].imshow(C2_with_bar)\n",
        "    axes[2].set_title(\"C2 TL-POL (raw + scale bar)\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    axes[3].imshow(proc_with_outline)\n",
        "    axes[3].set_title(f\"C2 Processed\\nThreshold={thr_val} ({C2_THRESH_MODE})\")\n",
        "    axes[3].axis(\"off\")\n",
        "\n",
        "    axes[4].imshow(final_rgb)\n",
        "    axes[4].set_title(\n",
        "        \"Final Composite\\n\"\n",
        "        f\"Pillar: {pillar_pct:.1f}% | Non-pillar: {nonpillar_pct:.1f}%\\n\"\n",
        "        f\"Crystal: {crystal_pct_total:.1f}% | Crystal/Non-pillar: {crystal_pct_nonpillar:.1f}%\"\n",
        "    )\n",
        "    axes[4].axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\n",
        "        f\"{base_key} | {C1_raw.shape[1]}Ã—{C1_raw.shape[0]} px | \"\n",
        "        f\"{FIELD_UM:.1f} Âµm FOV (~{um_per_px:.2f} Âµm/px)\",\n",
        "        fontsize=14,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save storyboard PNG\n",
        "    out_png = STORY_DIR / f\"{base_key}.storyboard.png\"\n",
        "    fig.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    metrics_rows.append({\n",
        "        \"base_key\": base_key,\n",
        "        \"c1_path\": str(c1_path),\n",
        "        \"c2_path\": str(c2_path),\n",
        "        \"mask_path\": str(mask_path),\n",
        "        \"c2_thresh_mode\": C2_THRESH_MODE,\n",
        "        \"c2_thresh_value\": int(thr_val),\n",
        "        \"pillar_pixels\": pillar_pixels,\n",
        "        \"nonpillar_pixels\": nonpillar_pixels,\n",
        "        \"crystal_pixels\": crystal_pixels,\n",
        "        \"pillar_pct_total\": pillar_pct,\n",
        "        \"nonpillar_pct_total\": nonpillar_pct,\n",
        "        \"crystal_pct_total\": crystal_pct_total,\n",
        "        \"crystal_pct_nonpillar\": crystal_pct_nonpillar,\n",
        "        \"storyboard_path\": str(out_png),\n",
        "    })\n",
        "\n",
        "# Save metrics table\n",
        "metrics_df = pd.DataFrame(metrics_rows)\n",
        "metrics_csv = OUT_ROOT / \"storyboard_metrics.csv\"\n",
        "metrics_df.to_csv(metrics_csv, index=False)\n",
        "\n",
        "print(\"\\nSaved storyboards:\", len(metrics_df))\n",
        "print(\"Saved metrics:\", metrics_csv.resolve())\n",
        "\n",
        "# -----------------------\n",
        "# Preview ALL storyboards inline\n",
        "# -----------------------\n",
        "print(f\"\\nPreviewing ALL storyboard PNG(s): {len(metrics_df)} total\\n\")\n",
        "\n",
        "for i in range(len(metrics_df)):\n",
        "    fp = Path(metrics_df.iloc[i][\"storyboard_path\"])\n",
        "    img = cv2.imread(str(fp))\n",
        "    if img is None:\n",
        "        print(\"Could not read:\", fp)\n",
        "        continue\n",
        "\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(fp.name, fontsize=10)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "metrics_df.head()\n"
      ],
      "metadata": {
        "id": "vuY7IFTZACap"
      },
      "id": "vuY7IFTZACap",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}